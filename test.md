# CV总结

## 深度神经网络训练技巧



### 模型集成

**模型集成** 多个模型组合起来可以产生一个更强大的模型

> 使用单一的基础学习算法，这样一来我们就有了以不同方式训练的同质弱学习器。这样得到的集成模型被称为「同质的」。然而，也有一些方法使用不同种类的基础学习算法：将一些异质的弱学习器组合成「异质集成模型」。

- bagging，同质弱学习器，相互独立地并行学习，并按照某种确定性的平均过程将它们组合起来。👉获得一个方差比其组成部分更小的集成模型

  

- boosting，同质弱学习器。高度自适应的方法顺序学习（每个基础模型都依赖于前面的模型），并按照某种确定性的策略将它们组合起来。

  👉偏置比其组成部分更低的强模型

  eg.如果想要使用树作为基础模型，我们将主要选择只有少许几层的较浅决策树。

  模型拟合的计算开销较低（参数化时自由度较低）

  * adaboosting，
  * gradient boosting，

- stacking，异质弱学习器，并行地学习它们，并通过训练「元模型」将它们组合起来，根据不同弱模型的预测结果输出一个最终的预测结果。👉偏置比其组成部分更低的强模型

